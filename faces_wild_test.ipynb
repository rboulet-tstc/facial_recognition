{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to explore packages for image processing and human face bounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall basic function calls for any cv2 project.\n",
    " - The color of the image can be changed with second param, greyscale/BW/color in the .imread() function.\n",
    " - The .imshow() function to get GUI to show image, first param is window title and second is image array. \n",
    " - The .waitkey() function to hold window on screen, param for int is milliseconds, 0 is until user exits. \n",
    " - The destroyAllWindows() function close all open cv2 windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and importing the image we want to analyze.\n",
    "image_path = \"C:/Users/rboulet.TOTALSYSTECH/OneDrive - Total Systems Technologies Corporation (TSTC)/Face Recognition/faces_in_wild_data/Bill_Gates/Bill_Gates_0001.jpg\"\n",
    "image_orig = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Convert the image we are analyzing using the haarcascades analyzer (pretrained).\n",
    "image_grey = cv2.cvtColor(image_orig, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Loading and applying the haarcascades analyzer from cv2 library.\n",
    "face_classifier = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_frontalface_alt.xml\")\n",
    "# Assigning face(s) found to python object to draw on original image.\n",
    "detected_objects = face_classifier.detectMultiScale(image_grey, minSize=(50,50))\n",
    "\n",
    "# Draw bounding box based on the face locations identified using the cascade classifier.\n",
    "# Docs for detected_objects returned object = (x, y, width, height).\n",
    "# Docs for drawing rectangle cv2 = cv2.rectangle(image, start_point:{x,y}, end_point, color, thickness)\n",
    "for (x, y, width, height) in detected_objects:\n",
    "    cv2.rectangle(image_orig, \n",
    "                  (x,y),\n",
    "                  (x + height, y + width),\n",
    "                  (0, 0, 250),\n",
    "                  4)\n",
    "\n",
    "\n",
    "# Show the original image with the rectangle for face drawn on it.\n",
    "cv2.imshow('Bill', image_orig)\n",
    "# Needed so kernel does not crash as well.\n",
    "cv2.waitKey(0)\n",
    "# This will just return -1 if not included vs kill window text, possibly for ensuring no background processes?\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the cell above into a function to call on a specific folder to see how it performs on all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension to read all images (.jpg wildcard) to an object for Bill Gates.\n",
    "bill_folder_all_jpg = 'faces_in_wild_data\\lfw-deepfunneled\\lfw-deepfunneled\\Bill_Gates\\*.jpg'\n",
    "bill_images = [cv2.imread(file) for file in glob.glob(bill_folder_all_jpg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(bill_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and applying the haarcascades analyzer from cv2 library.\n",
    "face_classifier = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "# Function to source different folders for facial bounding and return windows one after the other with results.\n",
    "def bound_faces(person: str) -> object:\n",
    "    person_folder_path = f'faces_in_wild_data\\lfw-deepfunneled\\lfw-deepfunneled\\{person}\\*.jpg'\n",
    "    person_images = [cv2.imread(file, cv2.IMREAD_COLOR) for file in glob.glob(person_folder_path)]\n",
    "\n",
    "    for image in person_images:\n",
    "        # Convert original image to greyscale.\n",
    "        image_grey = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Assigning face position found from facial classifier to draw on original image.\n",
    "        face_location = face_classifier.detectMultiScale(image_grey, minSize=(10,10))\n",
    "        \n",
    "        # Draw bounding box based on the face locations identified using the cascade classifier.\n",
    "        for (x, y, width, height) in face_location:\n",
    "            cv2.rectangle(image, \n",
    "                          (x,y),\n",
    "                          (x + height, y + width),\n",
    "                          (0, 250, 0),\n",
    "                          2)\n",
    "        \n",
    "        # Show the original image with the rectangle for face drawn on it.\n",
    "        cv2.imshow(person, image)\n",
    "        # Needed so kernel does not crash as well.\n",
    "        cv2.waitKey(0)\n",
    "        # This will just return -1 if not included vs kill window text, possibly for ensuring no background processes?\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return 'All Images Complete.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_faces('colin_Powell')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into face classification for testing whether or not images of persons are correctly identified based on input classes.\n",
    "The quesstions I have currently on this process:\n",
    "1. Is only a portion of the image used, e.g. the face when bounded is extracted, when classifying images of persons?\n",
    "2. What is a reasonable number of classes to attempt?\n",
    "3. Are there impacts to performance when an imbalanced training dataset is used.\n",
    "4. Can this be performed on both images and video?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Info pertaining to haarcascades classifier algorithm: </u>\n",
    "\n",
    "_\"This is done using the cv2::CascadeClassifier::detectMultiScale method, which returns boundary rectangles for the detected faces (i.e., x, y, w, h). It takes two parameters namely, scaleFactor and minNeighbors. ScaleFactor determines the factor of increase in window size which initially starts at size “minSize”, and after testing all windows of that size, the window is scaled up by the “scaleFactor”, and the window size goes up to “maxSize”. If the “scaleFactor” is large, (e.g., 2.0), there will be fewer steps, so detection will be faster, but we may miss objects whose size is between two tested scales. (default scale factor is 1.3). Higher the values of the “minNeighbors”, less will be the number of false positives, and less error will be in terms of false detection of faces. However, there is a chance of missing some unclear face traces as well.\"_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Is only a portion of the image used, e.g. the face when bounded is extracted, when classifying images of persons?__\n",
    "\n",
    " - The SIFT method is one of the techniques used to extract features of a face in order to compare to others. SIFT is built into opencv library. \n",
    " - SIFT is can be used regardless of size of image and orientation of image.\n",
    " - FAST is another method of feature extraction used for images. It is a corner detection method (LOOK UP) and is faster than SIFT which is useful when doing things like real time video capture and comparison.\n",
    " - ORB is another method to extract features. This is 'rotation invariant' (LOOK UP). SIFT and SURF are patented and this is OSS full license, and is apparently more efficient than SIFT and SURF (LOOK UP SURF)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exploring SIFT__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading SIFT algorithm from opencv library.\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Image path.\n",
    "image_path = 'faces_in_wild_data\\lfw-deepfunneled\\lfw-deepfunneled\\Bill_Gates\\Bill_Gates_0001.jpg'\n",
    "\n",
    "# Read original color image. Convert color image to gray and assign.\n",
    "image_orig = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "image_gray = cv2.cvtColor(image_orig, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Applying the SIFT algorithm to the gray image.\n",
    "keypoints = sift.detect(image_gray, None) # Check docs on method called and inputs/ouptuts.\n",
    "\n",
    "# Draw identified keypoints on the gray image.(LOOK UP this relative to previous without size).\n",
    "image_with_keypoints = cv2.drawKeypoints(image_gray, \n",
    "                                         keypoints, \n",
    "                                         image_orig, \n",
    "                                         flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Show the original image with the rectangle for face drawn on it.\n",
    "cv2.imshow('keypoints on image', image_with_keypoints)\n",
    "# Needed so kernel does not crash as well.\n",
    "cv2.waitKey(0)\n",
    "# This will just return -1 if not included vs kill window text, possibly for ensuring no background processes?\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exploring FAST algorithm for feature extraction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAST algorithm from opencv library.\n",
    "fast = cv2.FastFeatureDetector_create()\n",
    "\n",
    "# Detecting keypoints with FAST. \n",
    "keypoints_with_nonmax = fast.detect(image_gray, None)\n",
    "\n",
    "\n",
    "image_fast_keypoints = cv2.drawKeypoints(image_gray, \n",
    "                                 keypoints_with_nonmax, \n",
    "                                 image_orig, \n",
    "                                 color=(0,255,0),\n",
    "                                 flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "\n",
    "# Show the original image with the rectangle for face drawn on it.\n",
    "cv2.imshow('keypoints on image', image_fast_keypoints)\n",
    "# Needed so kernel does not crash as well.\n",
    "cv2.waitKey(0)\n",
    "# This will just return -1 if not included vs kill window text, possibly for ensuring no background processes?\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b25e07260771ac8fcdd024a70e90b652ca4be9d1b3dc5ece8a0c09e2f81efd08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
